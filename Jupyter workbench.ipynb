{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set default tensors to GPU tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Device Name: GeForce GTX 1080 Ti\n",
      "Current Device ID: 0 Device to use: <torch.cuda.device object at 0x0000019E4C86EC50>\n",
      "Total devices count: 1\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "torch.cuda.set_device(0)\n",
    "dtype = torch.cuda.FloatTensor\n",
    "print(\"Current Device Name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "print(\"Current Device ID:\",torch.cuda.current_device(), \"Device to use:\",torch.cuda.device(0))\n",
    "print(\"Total devices count:\", torch.cuda.device_count())\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, samples, image_dir, transform=None):\n",
    "        self.samples = samples\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_samples = self.samples[index]\n",
    "        steering_angle = float(batch_samples[3])\n",
    "        center_img, steering_angle_center = augment(self.image_dir, batch_samples[0], steering_angle)\n",
    "        left_img, steering_angle_left = augment(self.image_dir, batch_samples[1], steering_angle + 0.4)\n",
    "        right_img, steering_angle_right = augment(self.image_dir, batch_samples[2], steering_angle - 0.4)\n",
    "        center_img = self.transform(center_img)\n",
    "        left_img = self.transform(left_img)\n",
    "        right_img = self.transform(right_img)\n",
    "        return (center_img, float(steering_angle_center)),\\\n",
    "               (left_img, float(steering_angle_left)),\\\n",
    "               (right_img, float(steering_angle_right))\n",
    "               \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(87040, 512)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool(x)\n",
    "        num_features=self.num_flat_features(x)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# load the samples and split them into training and validation sets\n",
    "def read_samples(csv_filepath, validation_per = 0.2):\n",
    "    samples = []\n",
    "    with open(csv_filepath) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader, None)\n",
    "        for line in reader:                                                                 \n",
    "            samples.append(line)\n",
    "    validation_count = int(validation_per * len(samples))\n",
    "    training_count = len(samples) - validation_count\n",
    "    training_samples, validation_samples = random_split(samples,\\\n",
    "                                                        lengths = [training_count, validation_count])\n",
    "    return training_samples, validation_samples \n",
    "\n",
    "def augment(image_dir, imgName, angle):\n",
    "    name = image_dir + imgName.split('/')[-1]\n",
    "    current_image = cv2.imread(name)\n",
    "    current_image = current_image[65:-25, :, :]\n",
    "    if np.random.rand() < 0.5:\n",
    "        current_image = cv2.flip(current_image, 1)\n",
    "        angle = angle * -1.0  \n",
    "    return current_image, angle\n",
    "\n",
    "def eval_net(dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "    net.eval() # Why would I do this?\n",
    "    criterion = nn.MSELoss(reduction='sum')\n",
    "    for center, left, right in dataloader:\n",
    "        images, targets = center\n",
    "        images, targets = Variable(images).cuda(), Variable(targets.float()).cuda().unsqueeze(1)\n",
    "        outputs = net(images)\n",
    "        #_, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        #correct += (predicted == targets.data).sum()\n",
    "        loss = criterion(outputs, targets)\n",
    "        total_loss += loss.data.item()\n",
    "    net.train() # Why would I do this?\n",
    "    return total_loss / total\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "Start training...\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 1 train_loss: 0.01216 test_loss: 0.01009\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 2 train_loss: 0.01128 test_loss: 0.00956\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 3 train_loss: 0.01110 test_loss: 0.00956\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 4 train_loss: 0.00980 test_loss: 0.00829\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 5 train_loss: 0.00983 test_loss: 0.00851\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 6 train_loss: 0.00972 test_loss: 0.00899\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 7 train_loss: 0.00949 test_loss: 0.00830\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 8 train_loss: 0.00928 test_loss: 0.00795\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 9 train_loss: 0.00893 test_loss: 0.00784\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 10 train_loss: 0.00872 test_loss: 0.00774\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 11 train_loss: 0.00857 test_loss: 0.00773\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 12 train_loss: 0.00912 test_loss: 0.00826\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 13 train_loss: 0.00846 test_loss: 0.00774\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 14 train_loss: 0.00841 test_loss: 0.00767\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 15 train_loss: 0.00826 test_loss: 0.00776\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 16 train_loss: 0.00793 test_loss: 0.00759\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 17 train_loss: 0.00787 test_loss: 0.00750\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 18 train_loss: 0.00779 test_loss: 0.00755\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 19 train_loss: 0.00767 test_loss: 0.00767\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 20 train_loss: 0.00767 test_loss: 0.00753\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 21 train_loss: 0.00732 test_loss: 0.00747\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 22 train_loss: 0.00712 test_loss: 0.00758\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 23 train_loss: 0.00716 test_loss: 0.00755\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 24 train_loss: 0.00726 test_loss: 0.00805\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 25 train_loss: 0.00647 test_loss: 0.00756\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 26 train_loss: 0.00637 test_loss: 0.00726\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 27 train_loss: 0.00655 test_loss: 0.00788\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 28 train_loss: 0.00567 test_loss: 0.00717\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 29 train_loss: 0.00561 test_loss: 0.00739\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 30 train_loss: 0.00599 test_loss: 0.00810\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 31 train_loss: 0.00497 test_loss: 0.00737\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 32 train_loss: 0.00565 test_loss: 0.00836\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 33 train_loss: 0.00436 test_loss: 0.00719\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 34 train_loss: 0.00548 test_loss: 0.00856\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 35 train_loss: 0.00402 test_loss: 0.00721\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 36 train_loss: 0.00412 test_loss: 0.00783\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 37 train_loss: 0.00343 test_loss: 0.00734\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 38 train_loss: 0.00277 test_loss: 0.00716\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 39 train_loss: 0.00338 test_loss: 0.00810\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 40 train_loss: 0.00249 test_loss: 0.00768\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 41 train_loss: 0.00267 test_loss: 0.00815\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 42 train_loss: 0.00208 test_loss: 0.00738\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 43 train_loss: 0.00225 test_loss: 0.00793\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 44 train_loss: 0.00161 test_loss: 0.00751\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 45 train_loss: 0.00142 test_loss: 0.00760\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 46 train_loss: 0.00123 test_loss: 0.00734\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 47 train_loss: 0.00111 test_loss: 0.00743\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 48 train_loss: 0.00113 test_loss: 0.00731\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 49 train_loss: 0.00078 test_loss: 0.00716\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 50 train_loss: 0.00072 test_loss: 0.00724\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 51 train_loss: 0.00068 test_loss: 0.00753\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 52 train_loss: 0.00065 test_loss: 0.00751\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 53 train_loss: 0.00055 test_loss: 0.00727\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 54 train_loss: 0.00041 test_loss: 0.00723\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 55 train_loss: 0.00043 test_loss: 0.00710\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 56 train_loss: 0.00072 test_loss: 0.00737\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 57 train_loss: 0.00038 test_loss: 0.00741\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 58 train_loss: 0.00026 test_loss: 0.00725\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 59 train_loss: 0.00024 test_loss: 0.00723\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 60 train_loss: 0.00024 test_loss: 0.00716\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 61 train_loss: 0.00023 test_loss: 0.00736\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 62 train_loss: 0.00016 test_loss: 0.00733\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 63 train_loss: 0.00012 test_loss: 0.00722\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 64 train_loss: 0.00010 test_loss: 0.00726\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 65 train_loss: 0.00011 test_loss: 0.00712\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 66 train_loss: 0.00009 test_loss: 0.00723\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 67 train_loss: 0.00008 test_loss: 0.00726\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 68 train_loss: 0.00006 test_loss: 0.00721\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 69 train_loss: 0.00005 test_loss: 0.00711\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 70 train_loss: 0.00004 test_loss: 0.00716\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 71 train_loss: 0.00004 test_loss: 0.00724\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 72 train_loss: 0.00004 test_loss: 0.00724\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 73 train_loss: 0.00003 test_loss: 0.00730\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 74 train_loss: 0.00004 test_loss: 0.00722\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 75 train_loss: 0.00002 test_loss: 0.00715\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 76 train_loss: 0.00002 test_loss: 0.00716\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 77 train_loss: 0.00002 test_loss: 0.00728\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 78 train_loss: 0.00002 test_loss: 0.00712\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 79 train_loss: 0.00002 test_loss: 0.00731\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 80 train_loss: 0.00001 test_loss: 0.00716\n",
      "    Finish training this EPOCH, start evaluating...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 81 train_loss: 0.00001 test_loss: 0.00713\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 82 train_loss: 0.00001 test_loss: 0.00716\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 83 train_loss: 0.00001 test_loss: 0.00711\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 84 train_loss: 0.00001 test_loss: 0.00726\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 85 train_loss: 0.00001 test_loss: 0.00721\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 86 train_loss: 0.00001 test_loss: 0.00717\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 87 train_loss: 0.00001 test_loss: 0.00712\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 88 train_loss: 0.00001 test_loss: 0.00717\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 89 train_loss: 0.00001 test_loss: 0.00716\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 90 train_loss: 0.00000 test_loss: 0.00719\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 91 train_loss: 0.00000 test_loss: 0.00724\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 92 train_loss: 0.00000 test_loss: 0.00731\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 93 train_loss: 0.00000 test_loss: 0.00718\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 94 train_loss: 0.00000 test_loss: 0.00720\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 95 train_loss: 0.00000 test_loss: 0.00729\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 96 train_loss: 0.00000 test_loss: 0.00720\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 97 train_loss: 0.00000 test_loss: 0.00722\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 98 train_loss: 0.00000 test_loss: 0.00726\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 99 train_loss: 0.00000 test_loss: 0.00721\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 100 train_loss: 0.00000 test_loss: 0.00722\n",
      "Finished Training\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    BATCH_SIZE = 32 #mini_batch size\n",
    "    MAX_EPOCH = 100  #maximum epoch to train\n",
    "   \n",
    "    data_dir = sys.argv[1] # data directory\n",
    "    data_dir = \"./data/\"\n",
    "    train_samples, test_samples = read_samples(data_dir + 'driving_log.csv')\n",
    "     \n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    train_set = Dataset(train_samples, data_dir + 'IMG/', transform)\n",
    "    test_set = Dataset(test_samples, data_dir + 'IMG/', transform)\n",
    "\n",
    "    trainloader = DataLoader(train_set,\\\n",
    "                             batch_size=BATCH_SIZE,\\\n",
    "                             shuffle=True,\\\n",
    "                             num_workers=0)\n",
    "    testloader = DataLoader(test_set,\\\n",
    "                            batch_size=BATCH_SIZE,\\\n",
    "                            shuffle=False,\\\n",
    "                            num_workers=0)\n",
    "\n",
    "\n",
    "    print('Building model...')\n",
    "    net = Net().cuda()\n",
    "    net.benchmark = True\n",
    "    net.train() # Why would I do this?\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "    train_losses=list()\n",
    "    test_losses=list()\n",
    "\n",
    "    print('Start training...')\n",
    "    for epoch in range(MAX_EPOCH):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, (center, left, right) in enumerate(trainloader, 0):\n",
    "            # get the inputs\n",
    "            inputs, targets = center # only use center for now\n",
    "\n",
    "            # wrap them in Variable\n",
    "            inputs, targets = Variable(inputs).cuda(), Variable(targets.float()).cuda().unsqueeze(1)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print statistics\n",
    "            running_loss += loss.data.item()\n",
    "            if i % 500 == 499:    # print every 2000 mini-batches\n",
    "                print('    Step: %5d avg_batch_loss: %.5f' %\n",
    "                      (i + 1, running_loss / 500))\n",
    "                running_loss = 0.0\n",
    "        print('    Finish training this EPOCH, start evaluating...')\n",
    "        train_loss = eval_net(trainloader)\n",
    "        test_loss = eval_net(testloader)\n",
    "        print('EPOCH: %d train_loss: %.5f test_loss: %.5f' %\n",
    "              (epoch+1, train_loss, test_loss))\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "    print('Finished Training')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "now_str = str(datetime.now())[:10]\n",
    "plt.plot(train_losses, label='train_loss')\n",
    "plt.plot(test_losses, label='test_loss')\n",
    "plt.legend()\n",
    "name = \"./models/model_\" + str(now_str) + \"_100_Epoch_\" + str(min(test_losses))\n",
    "plt.savefig(name +\".png\")\n",
    "print('Saving model...')\n",
    "torch.save(net.state_dict(), name+\".pth\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
