{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set default tensors to GPU tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Device Name: GeForce GTX 1080 Ti\n",
      "Current Device ID: 0 Device to use: <torch.cuda.device object at 0x000002B103444BA8>\n",
      "Total devices count: 1\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "torch.cuda.set_device(0)\n",
    "dtype = torch.cuda.FloatTensor\n",
    "print(\"Current Device Name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "print(\"Current Device ID:\",torch.cuda.current_device(), \"Device to use:\",torch.cuda.device(0))\n",
    "print(\"Total devices count:\", torch.cuda.device_count())\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, samples, image_dir, transform=None):\n",
    "        self.samples = samples\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        batch_samples = self.samples[index]\n",
    "        steering_angle = float(batch_samples[3])\n",
    "        center_img, steering_angle_center = augment(self.image_dir, batch_samples[0], steering_angle)\n",
    "        left_img, steering_angle_left = augment(self.image_dir, batch_samples[1], steering_angle + 0.4)\n",
    "        right_img, steering_angle_right = augment(self.image_dir, batch_samples[2], steering_angle - 0.4)\n",
    "        center_img = self.transform(center_img)\n",
    "        left_img = self.transform(left_img)\n",
    "        right_img = self.transform(right_img)\n",
    "        return (center_img, float(steering_angle_center)),\\\n",
    "               (left_img, float(steering_angle_left)),\\\n",
    "               (right_img, float(steering_angle_right))\n",
    "               \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(87040, 512)\n",
    "        self.fc2 = nn.Linear(512, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool(x)\n",
    "        num_features=self.num_flat_features(x)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def read_samples(csv_filepath, validation_per = 0.2):\n",
    "    samples = []\n",
    "    with open(csv_filepath) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader, None)\n",
    "        for line in reader:                                                                 \n",
    "            samples.append(line)\n",
    "    validation_count = int(validation_per * len(samples))\n",
    "    training_count = len(samples) - validation_count\n",
    "    training_samples, validation_samples = random_split(samples,\\\n",
    "                                                        lengths = [training_count, validation_count])\n",
    "    return training_samples, validation_samples \n",
    "\n",
    "def augment(image_dir, imgName, angle):\n",
    "    name = image_dir + imgName.split('/')[-1]\n",
    "    current_image = cv2.imread(name)\n",
    "    current_image = current_image[65:-25, :, :]\n",
    "    if np.random.rand() < 0.5:\n",
    "        current_image = cv2.flip(current_image, 1)\n",
    "        angle = angle * -1.0  \n",
    "    return current_image, angle\n",
    "\n",
    "def eval_net(dataloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "    net.eval() # Why would I do this?\n",
    "    criterion = nn.MSELoss(reduction='sum')\n",
    "    for center, left, right in dataloader:\n",
    "        for inputs, targets in [center, left, right]:\n",
    "            inputs, targets = Variable(inputs).cuda(),\\\n",
    "                              Variable(targets.float()).cuda().unsqueeze(1)\n",
    "            outputs = net(inputs)\n",
    "            total += targets.size(0)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.data.item()\n",
    "    net.train() # Why would I do this?\n",
    "    return total_loss / total\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "Start training...\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 1 train_loss: 0.09558 test_loss: 0.09591\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 2 train_loss: 0.09294 test_loss: 0.09343\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 3 train_loss: 0.09428 test_loss: 0.09527\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 4 train_loss: 0.09583 test_loss: 0.09661\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 5 train_loss: 0.09706 test_loss: 0.09812\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 6 train_loss: 0.08976 test_loss: 0.09047\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 7 train_loss: 0.09537 test_loss: 0.09657\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 8 train_loss: 0.09293 test_loss: 0.09402\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 9 train_loss: 0.09395 test_loss: 0.09507\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 10 train_loss: 0.08946 test_loss: 0.09029\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 11 train_loss: 0.09109 test_loss: 0.09223\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 12 train_loss: 0.09135 test_loss: 0.09229\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 13 train_loss: 0.08804 test_loss: 0.08879\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 14 train_loss: 0.08929 test_loss: 0.09065\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 15 train_loss: 0.08766 test_loss: 0.08892\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 16 train_loss: 0.08661 test_loss: 0.08749\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 17 train_loss: 0.08506 test_loss: 0.08680\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 18 train_loss: 0.08659 test_loss: 0.08784\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 19 train_loss: 0.08544 test_loss: 0.08754\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 20 train_loss: 0.08253 test_loss: 0.08417\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 21 train_loss: 0.08291 test_loss: 0.08458\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 22 train_loss: 0.07921 test_loss: 0.08087\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 23 train_loss: 0.08181 test_loss: 0.08346\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 24 train_loss: 0.08167 test_loss: 0.08369\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 25 train_loss: 0.08436 test_loss: 0.08718\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 26 train_loss: 0.08027 test_loss: 0.08227\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 27 train_loss: 0.08315 test_loss: 0.08513\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 28 train_loss: 0.08112 test_loss: 0.08335\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 29 train_loss: 0.08006 test_loss: 0.08246\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 30 train_loss: 0.08139 test_loss: 0.08369\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 31 train_loss: 0.08267 test_loss: 0.08491\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 32 train_loss: 0.07997 test_loss: 0.08232\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 33 train_loss: 0.08370 test_loss: 0.08638\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 34 train_loss: 0.08228 test_loss: 0.08482\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 35 train_loss: 0.08248 test_loss: 0.08501\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 36 train_loss: 0.08153 test_loss: 0.08463\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 37 train_loss: 0.08259 test_loss: 0.08544\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 38 train_loss: 0.08217 test_loss: 0.08460\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 39 train_loss: 0.08175 test_loss: 0.08431\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 40 train_loss: 0.08153 test_loss: 0.08376\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 41 train_loss: 0.08157 test_loss: 0.08396\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 42 train_loss: 0.08188 test_loss: 0.08423\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 43 train_loss: 0.08144 test_loss: 0.08388\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 44 train_loss: 0.08204 test_loss: 0.08481\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 45 train_loss: 0.08246 test_loss: 0.08512\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 46 train_loss: 0.08224 test_loss: 0.08471\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 47 train_loss: 0.08192 test_loss: 0.08443\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 48 train_loss: 0.08189 test_loss: 0.08455\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 49 train_loss: 0.08195 test_loss: 0.08453\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 50 train_loss: 0.08186 test_loss: 0.08416\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 51 train_loss: 0.08196 test_loss: 0.08437\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 52 train_loss: 0.08183 test_loss: 0.08450\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 53 train_loss: 0.08177 test_loss: 0.08425\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 54 train_loss: 0.08209 test_loss: 0.08451\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 55 train_loss: 0.08176 test_loss: 0.08446\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 56 train_loss: 0.08231 test_loss: 0.08470\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 57 train_loss: 0.08221 test_loss: 0.08475\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 58 train_loss: 0.08177 test_loss: 0.08419\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 59 train_loss: 0.08187 test_loss: 0.08437\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 60 train_loss: 0.08195 test_loss: 0.08455\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 61 train_loss: 0.08179 test_loss: 0.08450\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 62 train_loss: 0.08175 test_loss: 0.08433\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 63 train_loss: 0.08193 test_loss: 0.08441\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 64 train_loss: 0.08208 test_loss: 0.08462\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 65 train_loss: 0.08208 test_loss: 0.08488\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 66 train_loss: 0.08186 test_loss: 0.08443\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 67 train_loss: 0.08182 test_loss: 0.08418\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 68 train_loss: 0.08174 test_loss: 0.08443\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 69 train_loss: 0.08186 test_loss: 0.08458\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 70 train_loss: 0.08206 test_loss: 0.08435\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 71 train_loss: 0.08194 test_loss: 0.08445\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 72 train_loss: 0.08199 test_loss: 0.08468\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 73 train_loss: 0.08185 test_loss: 0.08440\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 74 train_loss: 0.08200 test_loss: 0.08462\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 75 train_loss: 0.08190 test_loss: 0.08439\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 76 train_loss: 0.08182 test_loss: 0.08456\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 77 train_loss: 0.08188 test_loss: 0.08433\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 78 train_loss: 0.08194 test_loss: 0.08445\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 79 train_loss: 0.08200 test_loss: 0.08463\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 80 train_loss: 0.08196 test_loss: 0.08431\n",
      "    Finish training this EPOCH, start evaluating...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 81 train_loss: 0.08202 test_loss: 0.08447\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 82 train_loss: 0.08195 test_loss: 0.08444\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 83 train_loss: 0.08201 test_loss: 0.08460\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 84 train_loss: 0.08176 test_loss: 0.08440\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 85 train_loss: 0.08184 test_loss: 0.08441\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 86 train_loss: 0.08199 test_loss: 0.08463\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 87 train_loss: 0.08192 test_loss: 0.08460\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 88 train_loss: 0.08195 test_loss: 0.08466\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 89 train_loss: 0.08194 test_loss: 0.08436\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 90 train_loss: 0.08180 test_loss: 0.08436\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 91 train_loss: 0.08202 test_loss: 0.08452\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 92 train_loss: 0.08188 test_loss: 0.08445\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 93 train_loss: 0.08191 test_loss: 0.08451\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 94 train_loss: 0.08204 test_loss: 0.08435\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 95 train_loss: 0.08201 test_loss: 0.08450\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 96 train_loss: 0.08182 test_loss: 0.08438\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 97 train_loss: 0.08193 test_loss: 0.08447\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 98 train_loss: 0.08200 test_loss: 0.08445\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 99 train_loss: 0.08192 test_loss: 0.08445\n",
      "    Finish training this EPOCH, start evaluating...\n",
      "EPOCH: 100 train_loss: 0.08187 test_loss: 0.08445\n",
      "Finished Training\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    BATCH_SIZE = 32 #mini_batch size\n",
    "    MAX_EPOCH = 100  #maximum epoch to train\n",
    "   \n",
    "    data_dir = \"./data/\"\n",
    "\n",
    "    train_samples, test_samples = read_samples(data_dir + 'driving_log.csv')                     \n",
    "     \n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    train_set = Dataset(train_samples, data_dir + 'IMG/', transform)\n",
    "    test_set = Dataset(test_samples, data_dir + 'IMG/', transform)\n",
    "\n",
    "    trainloader = DataLoader(train_set,\\\n",
    "                             batch_size=BATCH_SIZE,\\\n",
    "                             shuffle=True,\\\n",
    "                             num_workers=0)\n",
    "    testloader = DataLoader(test_set,\\\n",
    "                            batch_size=BATCH_SIZE,\\\n",
    "                            shuffle=False,\\\n",
    "                            num_workers=0)\n",
    "\n",
    "\n",
    "    print('Building model...')\n",
    "    net = Net().cuda()\n",
    "    net.train() # Why would I do this?\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "    train_losses=list()\n",
    "    test_losses=list()\n",
    "\n",
    "    print('Start training...')\n",
    "    for epoch in range(MAX_EPOCH):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, (center, left, right) in enumerate(trainloader, 0):\n",
    "            for inputs, targets in [center, left, right]:\n",
    "                # get the inputs\n",
    "                inputs, targets = center # only use center for now\n",
    "                # wrap them in Variable\n",
    "                inputs, targets = Variable(inputs).cuda(),\\\n",
    "                                  Variable(targets.float()).cuda().unsqueeze(1)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                # print statistics\n",
    "                running_loss += loss.data.item()\n",
    "            if i % 500 == 499:    # print every 2000 mini-batches\n",
    "                print('    Step: %5d avg_batch_loss: %.5f' %\n",
    "                      (i + 1, running_loss / 500))\n",
    "                running_loss = 0.0\n",
    "        print('    Finish training this EPOCH, start evaluating...')\n",
    "        train_loss = eval_net(trainloader)\n",
    "        test_loss = eval_net(testloader)\n",
    "        print('EPOCH: %d train_loss: %.5f test_loss: %.5f' %\n",
    "              (epoch+1, train_loss, test_loss))\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "    print('Finished Training')\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "now_str = str(datetime.now())[:10]\n",
    "plt.plot(train_losses, label='train_loss')\n",
    "plt.plot(test_losses, label='test_loss')\n",
    "plt.legend()\n",
    "name = \"./models/model_\" + str(now_str) + \"_100_new_Epoch_\" + str(min(test_losses))\n",
    "plt.savefig(name +\".png\")\n",
    "print('Saving model...')\n",
    "torch.save(net.state_dict(), name+\".pth\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
